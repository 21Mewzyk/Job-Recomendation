{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< INSTALLATION GUIDE>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> \n",
    "\n",
    "'''pip install nltk\n",
    "\n",
    "pip install spacy==2.3.5\n",
    "\n",
    "pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz\n",
    "\n",
    "pip install pyresparser'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pdfplumber\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "from string import punctuation\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.probability import FreqDist\n",
    "from heapq import nlargest\n",
    "from collections import defaultdict\n",
    "import pandas as pd \n",
    "from nltk.collocations import *\n",
    "import base64,random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pyresparser import ResumeParser\n",
    "import pdfplumber\n",
    "import re\n",
    "\n",
    "# Define the directory containing resumes\n",
    "resumes_dir = 'cv_to_df/'\n",
    "resumes_dir_full_path = os.path.abspath(resumes_dir)\n",
    "\n",
    "def pdf_to_base64(file_path):\n",
    "    \n",
    "    encoded_pdf = base64.b64encode(file_path.read()).decode('utf-8')\n",
    "\n",
    "    return encoded_pdf\n",
    "\n",
    "def extract_text_from_pdf(filepath):\n",
    "    with pdfplumber.open(filepath) as pdf:\n",
    "        text = \"\"\n",
    "        pages = pdf.pages\n",
    "        for page in pages:\n",
    "            text += page.extract_text(x_tolerance=2)\n",
    "    return text\n",
    "\n",
    "# Create an empty DataFrame object to store the extracted data\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Iterate through all files in the resumes directory\n",
    "for filename in os.listdir(resumes_dir):\n",
    "    if filename.endswith('.pdf'):  # Check if the file is a PDF\n",
    "        # Apply the ResumeParser function to the current file and append the extracted data to the DataFrame\n",
    "        data = ResumeParser(os.path.join(resumes_dir, filename)).get_extracted_data()\n",
    "        # Add a new column to the DataFrame containing the file path\n",
    "        data['file_path'] = os.path.join(resumes_dir, filename)\n",
    "        # Append the extracted data to the DataFrame\n",
    "        df = df.append(data, ignore_index=True)\n",
    "\n",
    "# Extract text from all PDFs in the resumes directory and create a new DataFrame\n",
    "data = []\n",
    "for filename in os.listdir(resumes_dir):\n",
    "    if filename.endswith('.pdf'):\n",
    "        filepath = os.path.join(resumes_dir, filename)\n",
    "        resume_data = extract_text_from_pdf(filepath)\n",
    "        data.append({'file_path': filepath, 'All': resume_data})\n",
    "df2 = pd.DataFrame(data)\n",
    "\n",
    "# Merge the two data frames on the \"file_path\" column\n",
    "merged_df = pd.merge(df, df2, on='file_path')\n",
    "merged_df.drop(columns=[\"college_name\",\"company_names\",\"designation\",\"experience\",\"total_experience\"], axis=1, inplace=True) # dropping unwanted col\n",
    "\n",
    "# Define the regex pattern to match unwanted characters\n",
    "unwanted_chars_pattern = r'[^a-zA-Z !@#$%&*_+-=|\\:\";<>,./()[\\]{}\\']'\n",
    "for col in ['skills','degree', 'All']:\n",
    "    merged_df[col] = merged_df[col].apply(lambda x: re.sub(unwanted_chars_pattern, '', str(x)))\n",
    "\n",
    "\n",
    "merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = merged_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('cv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"cv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pyresparser import ResumeParser\n",
    "import pdfplumber\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_base64(file_path):\n",
    "    #with pdfplumber.open(filepath) as pdf\n",
    "    with open(file_path, 'rb') as f:\n",
    "    \n",
    "        encoded_pdf = base64.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "    return encoded_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_files=[]\n",
    "for i in df[\"file_path\"].values:\n",
    "    print()\n",
    "    encoded_files.append(pdf_to_base64(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pdf_to_base64\"]=encoded_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"updated_cv.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "d86ab636b363cb32d3f7578512f6396b4a169d210dbf8b4d547e88bd9fd74388"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
