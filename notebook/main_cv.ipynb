{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa0e6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pdfplumber\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "from string import punctuation\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.probability import FreqDist\n",
    "from heapq import nlargest\n",
    "from collections import defaultdict\n",
    "import pandas as pd \n",
    "from nltk.collocations import *\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9617bac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd='''Role - Senior Big Data Engineer\n",
    "Required Technical skills - Big Data, Python, Spark, Data brick, data Spark\n",
    "Desired Experience Range - 5 + years\n",
    "Location of Requirement - PAN India\n",
    "Desired Competencies\n",
    "Must-Have\n",
    "Good hands on experience in Python programming\n",
    "· Data Engineering experience using AWS core services (Lambda, Glue, EMR and RedShift)\n",
    "· Required skill set- SQL, Airflow · Must – Have Experience with snowflake\n",
    "\n",
    "· Responsibility – Will be accountable for build/test complex data pipelines (batch and near real time) · Expectation – Readable documentation of all the components being develop · Experience in writing SQLs and stored procedures · Working experience with RDBMS (Oracle / Teradata)\n",
    "Good-to-Have\n",
    "· Good understanding of Data warehouse\n",
    "· Familiarize in ETL tools like Informatica\n",
    "· Experience working with NoSQL database like DynamoDB or MongoDB .'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61836018",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def remove_stuff(jd):\n",
    "    jd_clean = jd.replace(\"\\xa0\", \"\").replace(\"/\", \"\").replace(\".\", \". \").replace(\"●\", \"\")\n",
    "    return jd_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565472f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv(): #cleaned, processed, nlped cv content\n",
    "    url='cv.csv'\n",
    "    return pd.read_csv(url) \n",
    "# db_expander = st.beta_expander(label='Submitted resume:')\n",
    "# with db_expander:\n",
    "df = get_cv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf70694b",
   "metadata": {},
   "source": [
    "# checking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb26ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad99cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcb77a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"All\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a58c5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# job discription entered by recuriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa25242",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7996de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp(x):\n",
    "    word_sent = word_tokenize(x.lower().replace(\"\\n\",\"\"))\n",
    "    _stopwords = set(stopwords.words('english') + list(punctuation)+list(\"●\")+list('–')+list('’'))\n",
    "    word_sent=[word for word in word_sent if word not in _stopwords]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    clean_text = [lemmatizer.lemmatize(word) for word in word_tokenize(\" \".join(word_sent))]\n",
    "#     return \" \".join(NLP_Processed_CV)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688d68ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "NLP_Processed_JD=nlp(jd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeb7806",
   "metadata": {},
   "outputs": [],
   "source": [
    "NLP_Processed_JD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82ec48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b19ae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_df=pd.DataFrame()\n",
    "# jd_df['hi']=['I']\n",
    "jd_df['jd']=[' '.join(NLP_Processed_JD)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e36e0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_df['jd'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34d5cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_jd=jd_df['jd'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99315839",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddd33d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"All\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f688966",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_data=[]\n",
    "for i in range(len(df[\"All\"])):\n",
    "    NLP_Processed_cv=nlp(df[\"All\"].values[i])\n",
    "    cv_data.append(NLP_Processed_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3889033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95fc496",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_=[]\n",
    "for i in cv_data:\n",
    "    cv_.append([' '.join(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b490ca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2318480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clean_all\"]=pd.DataFrame(cv_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d0beaa",
   "metadata": {},
   "source": [
    "# Recomendation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d6083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77d270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendation(top, df_all, scores):\n",
    "    recommendation = pd.DataFrame(columns = ['name', 'degree',\"email\",'Unnamed: 0','mobile_number','skills','no_of_pages','score'])\n",
    "    count = 0\n",
    "    for i in top:\n",
    "#         recommendation.at[count, 'ApplicantID'] = u\n",
    "        \n",
    "        recommendation.at[count, 'name'] = df['name'][i]\n",
    "        recommendation.at[count, 'degree'] = df['degree'][i]\n",
    "        recommendation.at[count, 'email'] = df['email'][i]\n",
    "        recommendation.at[count, 'Unnamed: 0'] = df.index[i]\n",
    "        recommendation.at[count, 'mobile_number'] = df['mobile_number'][i]\n",
    "        recommendation.at[count, 'skills'] = df['skills'][i]\n",
    "        recommendation.at[count, 'no_of_pages'] = df['no_of_pages'][i]\n",
    "        recommendation.at[count, 'score'] =  scores[count]\n",
    "        count += 1\n",
    "    return recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74111256",
   "metadata": {},
   "source": [
    "# cosine_similarity + TfidfVectorizer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efbd71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "def TFIDF(scraped_data, cv):\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "    # TF-IDF Scraped data\n",
    "    tfidf_jobid = tfidf_vectorizer.fit_transform(scraped_data)\n",
    "\n",
    "    # TF-IDF CV\n",
    "    user_tfidf = tfidf_vectorizer.transform(cv)\n",
    "\n",
    "    # Using cosine_similarity on (Scraped data) & (CV)\n",
    "    cos_similarity_tfidf = map(lambda x: cosine_similarity(user_tfidf,x),tfidf_jobid)\n",
    "\n",
    "    output2 = list(cos_similarity_tfidf)\n",
    "    return output2\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dfd932",
   "metadata": {},
   "outputs": [],
   "source": [
    "output2 = TFIDF(df[\"clean_all\"],jd_df['jd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578410c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577cba82",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = sorted(range(len(output2)), key=lambda i: output2[i], reverse=True)[:100]\n",
    "list_scores = [output2[i][0][0] for i in top]\n",
    "TF=get_recommendation(top,df, list_scores)\n",
    "TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266ecc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d874409",
   "metadata": {},
   "source": [
    "# cosine_similarity + CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d2a48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "count_jobid = count_vectorizer.fit_transform(df[\"clean_all\"]) #converting job data into vectors using count vectorizers\n",
    "count_jobid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b9da12",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_count = count_vectorizer.transform(jd_df['jd'])#converting user cv data into vectors using count vectorizers\n",
    "user_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31394beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe95c255",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_similarity_countv = map(lambda x: cosine_similarity(user_count, x),count_jobid)\n",
    "output3 = list(cos_similarity_countv)\n",
    "#output3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1558e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45c5a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = sorted(range(len(output3)), key=lambda i: output3[i], reverse=True)[:100]\n",
    "list_scores = [output3[i][0][0] for i in top]\n",
    "cv=get_recommendation(top, df, list_scores)\n",
    "cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8331212a",
   "metadata": {},
   "source": [
    "# TfidfVectorizer + NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75895b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def KNN(scraped_data, cv):\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "    \n",
    "    KNN = NearestNeighbors(n_neighbors=7,p=2)\n",
    "    KNN.fit(tfidf_vectorizer.fit_transform(scraped_data))\n",
    "#     NNs = KNN.kneighbors(tfidf_vectorizer.transform(cv), return_distance=True)\n",
    "    NNs = KNN.kneighbors(tfidf_vectorizer.transform(cv))\n",
    "    top = NNs[1][0][1:]\n",
    "    index_score = NNs[0][0][1:]\n",
    "\n",
    "    knn = get_recommendation(top, df, index_score)\n",
    "    return knn\n",
    "\n",
    "knn = KNN(df['clean_all'], jd_df['jd'])\n",
    "knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25641af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "knn.to_csv('knn_cv.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a45f347",
   "metadata": {},
   "source": [
    "# Combined TFIDF, CV and KNN result together, to make a dataframe \"final\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cfb63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b1fd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge1 = knn[['Unnamed: 0','name', 'score']].merge(TF[['Unnamed: 0','score']], on= \"Unnamed: 0\")\n",
    "final = merge1.merge(cv[['Unnamed: 0','score']], on = 'Unnamed: 0')\n",
    "final = final.rename(columns={\"score_x\": \"KNN\", \"score_y\": \"TF-IDF\",\"score\": \"CV\"})\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59dcf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a566c8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale it\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "slr = MinMaxScaler()\n",
    "final[[\"KNN\", \"TF-IDF\", 'CV']] = slr.fit_transform(final[[\"KNN\", \"TF-IDF\", 'CV']])\n",
    "\n",
    "# Multiply by weights\n",
    "final['KNN'] = (1-final['KNN'])/3\n",
    "final['TF-IDF'] = final['TF-IDF']/3\n",
    "final['CV'] = final['CV']/3\n",
    "final['Final'] = final['KNN']+final['TF-IDF']+final['CV']\n",
    "final.sort_values(by=\"Final\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e00867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final.to_csv('final.csv', index=False)\n",
    "final2 = final.sort_values(by=\"Final\", ascending=False).copy()\n",
    "final2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690f728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final2.merge(df, on=\"JobID\")\n",
    "final_df = df.merge(final2, on='Unnamed: 0')\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc145460",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308d76f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db326017",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "d86ab636b363cb32d3f7578512f6396b4a169d210dbf8b4d547e88bd9fd74388"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
